{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d32c6e-cd6a-4e48-8b0c-9bb32da02c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cbbf796-6c0a-4e1d-a891-24389bb8aaf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Flow ID  Source IP  Source Port  Destination IP  Destination Port  \\\n",
      "0    62015       1261      51885.0            1599              53.0   \n",
      "1    58525       1261      16641.0            1599              53.0   \n",
      "2    33764       1256      15954.0            1599              53.0   \n",
      "3    33749       1256      15744.0            1599              53.0   \n",
      "4    34500       1256      28467.0            1599              53.0   \n",
      "\n",
      "   Protocol  Timestamp  Flow Duration  Total Fwd Packets  \\\n",
      "0      17.0        181        76978.0                2.0   \n",
      "1      17.0        181        78120.0                2.0   \n",
      "2      17.0        181          205.0                2.0   \n",
      "3      17.0        181          169.0                2.0   \n",
      "4      17.0        181          297.0                2.0   \n",
      "\n",
      "   Total Backward Packets  ...  min_seg_size_forward  Active Mean  Active Std  \\\n",
      "0                     2.0  ...                  32.0          0.0         0.0   \n",
      "1                     2.0  ...                  32.0          0.0         0.0   \n",
      "2                     2.0  ...                  32.0          0.0         0.0   \n",
      "3                     2.0  ...                  32.0          0.0         0.0   \n",
      "4                     2.0  ...                  32.0          0.0         0.0   \n",
      "\n",
      "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
      "0         0.0         0.0        0.0       0.0       0.0       0.0  BENIGN  \n",
      "1         0.0         0.0        0.0       0.0       0.0       0.0  BENIGN  \n",
      "2         0.0         0.0        0.0       0.0       0.0       0.0  BENIGN  \n",
      "3         0.0         0.0        0.0       0.0       0.0       0.0  BENIGN  \n",
      "4         0.0         0.0        0.0       0.0       0.0       0.0  BENIGN  \n",
      "\n",
      "[5 rows x 84 columns]\n",
      "      Flow ID  Source IP  Source Port  Destination IP  Destination Port  \\\n",
      "7262    10247       1001        443.0            1603           51954.0   \n",
      "7263    15216       1263      62108.0            1590              53.0   \n",
      "7264    89865       4038          0.0            4913               0.0   \n",
      "7265    61697       1261      48645.0            1599              53.0   \n",
      "7266    14320       1263      61212.0            1590              53.0   \n",
      "\n",
      "      Protocol  Timestamp  Flow Duration  Total Fwd Packets  \\\n",
      "7262       6.0        130            3.0                2.0   \n",
      "7263      17.0        130       110225.0                1.0   \n",
      "7264       0.0        130    119994187.0               83.0   \n",
      "7265      17.0        130        45557.0                2.0   \n",
      "7266      17.0        130       692649.0                1.0   \n",
      "\n",
      "      Total Backward Packets  ...  min_seg_size_forward  Active Mean  \\\n",
      "7262                     0.0  ...                  20.0        0.000   \n",
      "7263                     1.0  ...                  20.0        0.000   \n",
      "7264                     0.0  ...                   0.0  4397194.167   \n",
      "7265                     2.0  ...                  20.0        0.000   \n",
      "7266                     1.0  ...                  20.0        0.000   \n",
      "\n",
      "       Active Std  Active Max  Active Min   Idle Mean     Idle Std  \\\n",
      "7262        0.000         0.0         0.0         0.0        0.000   \n",
      "7263        0.000         0.0         0.0         0.0        0.000   \n",
      "7264  7971475.641  19900000.0        65.0  10400000.0  4150499.041   \n",
      "7265        0.000         0.0         0.0         0.0        0.000   \n",
      "7266        0.000         0.0         0.0         0.0        0.000   \n",
      "\n",
      "        Idle Max   Idle Min   Label  \n",
      "7262         0.0        0.0  BENIGN  \n",
      "7263         0.0        0.0  BENIGN  \n",
      "7264  19300000.0  5960934.0  BENIGN  \n",
      "7265         0.0        0.0  BENIGN  \n",
      "7266         0.0        0.0  BENIGN  \n",
      "\n",
      "[5 rows x 84 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/home/sid/Documents/6610/csv/web_attacks_balanced.csv')\n",
    "\n",
    "print(data.head())\n",
    "print(data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99baa1d-cbc0-42bd-a1e2-5f801f0f39a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow ID             0\n",
      "Source IP           0\n",
      "Source Port         0\n",
      "Destination IP      0\n",
      "Destination Port    0\n",
      "                   ..\n",
      "Idle Mean           0\n",
      "Idle Std            0\n",
      "Idle Max            0\n",
      "Idle Min            0\n",
      "Label               0\n",
      "Length: 84, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Extract features and labels\n",
    "features = [\n",
    "    'Protocol', 'Total Length of Fwd Packets', 'Flow Duration', \n",
    "    'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packet Length Max', \n",
    "    'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', \n",
    "    'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', \n",
    "    'Bwd Packet Length Std', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', \n",
    "    'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', \n",
    "    'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', \n",
    "    'Bwd IAT Min'\n",
    "]\n",
    "X = data[features]\n",
    "y = data['Label']\n",
    "\n",
    "# Encode the 'Protocol' column using one-hot encoding\n",
    "X_encoded = pd.get_dummies(X, columns=['Protocol'])\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c149a086-4ae2-4b6f-9eb6-4248b0450c32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/data/python/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 0.1003\n",
      "Epoch 2/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 0.0097\n",
      "Epoch 3/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 0.0042\n",
      "Epoch 4/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 0.0020\n",
      "Epoch 5/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.0016\n",
      "Epoch 6/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 0.0013\n",
      "Epoch 7/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 0.0013\n",
      "Epoch 8/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.0012\n",
      "Epoch 9/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 0.0011 \n",
      "Epoch 10/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 0.0010 \n",
      "Epoch 11/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 9.1312e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 8.7477e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - loss: 9.1779e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 8.4061e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 8.2441e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 7.8764e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 7.6369e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 7.7063e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 7.5427e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 7.5164e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 6.7966e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 6.9072e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 6.5705e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 6.2774e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 6.4378e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 6.3963e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 5.9323e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 5.9696e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - loss: 6.2561e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 6.0696e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step\n",
      "Autoencoder anomaly points:\n",
      "Label\n",
      "BENIGN                        340\n",
      "Web Attack – XSS               19\n",
      "Web Attack – Brute Force        4\n",
      "Web Attack – Sql Injection      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define autoencoder model\n",
    "input_dim = X_scaled.shape[1]\n",
    "encoding_dim = 10\n",
    "\n",
    "autoencoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(encoding_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(input_dim, activation='sigmoid')\n",
    "])\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=30, batch_size=32)\n",
    "autoencoder.save('autoencoder_model.h5')\n",
    "\n",
    "# Use the trained autoencoder for anomaly detection\n",
    "reconstructed = autoencoder.predict(X_scaled)\n",
    "mse = np.mean(np.power(X_scaled - reconstructed, 2), axis=1)\n",
    "threshold = np.percentile(mse, 95)  # Adjust threshold if needed\n",
    "anomalypoints_autoencoder = data[mse > threshold]\n",
    "\n",
    "print(\"Autoencoder anomaly points:\")\n",
    "print(anomalypoints_autoencoder['Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a766d4a7-abb4-4faa-af77-9027846c7c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Anomalies:       Flow ID  Source IP  Source Port  Destination IP  Destination Port  \\\n",
      "6       41742       1258      49412.0            1599             135.0   \n",
      "8       71450       1267      52360.0            1599             389.0   \n",
      "10      49745       1258      49438.0            1599              88.0   \n",
      "11      75608       1267      49181.0            1599              88.0   \n",
      "13      75683       1268       1029.0            1599           49671.0   \n",
      "...       ...        ...          ...             ...               ...   \n",
      "7248    87068       3937        443.0            1603           52076.0   \n",
      "7256    85763       1267      51967.0            2125             443.0   \n",
      "7261    87598       1268       4632.0            1601           23744.0   \n",
      "7264    89865       4038          0.0            4913               0.0   \n",
      "7266    14320       1263      61212.0            1590              53.0   \n",
      "\n",
      "      Protocol  Timestamp  Flow Duration  Total Fwd Packets  \\\n",
      "6          6.0        182     23241857.0               23.0   \n",
      "8         17.0        182          114.0                2.0   \n",
      "10         6.0        182          501.0                7.0   \n",
      "11         6.0        182          943.0                9.0   \n",
      "13         6.0        182     26261439.0               21.0   \n",
      "...        ...        ...            ...                ...   \n",
      "7248       6.0        127       999697.0                2.0   \n",
      "7256       6.0        129    119963730.0               23.0   \n",
      "7261       6.0        129        31217.0               15.0   \n",
      "7264       0.0        130    119994187.0               83.0   \n",
      "7266      17.0        130       692649.0                1.0   \n",
      "\n",
      "      Total Backward Packets  ...  min_seg_size_forward  Active Mean  \\\n",
      "6                       14.0  ...                  20.0    81819.500   \n",
      "8                        2.0  ...                  20.0        0.000   \n",
      "10                       4.0  ...                  20.0        0.000   \n",
      "11                       6.0  ...                  20.0        0.000   \n",
      "13                      14.0  ...                  20.0        0.000   \n",
      "...                      ...  ...                   ...          ...   \n",
      "7248                     0.0  ...                  20.0        0.000   \n",
      "7256                    20.0  ...                  20.0   175960.250   \n",
      "7261                     6.0  ...                  20.0        0.000   \n",
      "7264                     0.0  ...                   0.0  4397194.167   \n",
      "7266                     1.0  ...                  20.0        0.000   \n",
      "\n",
      "        Active Std  Active Max  Active Min    Idle Mean      Idle Std  \\\n",
      "6     3.227872e+04    104644.0     58995.0   5590125.50  4.467607e+05   \n",
      "8     0.000000e+00         0.0         0.0         0.00  0.000000e+00   \n",
      "10    0.000000e+00         0.0         0.0         0.00  0.000000e+00   \n",
      "11    0.000000e+00         0.0         0.0         0.00  0.000000e+00   \n",
      "13    0.000000e+00         0.0         0.0         0.00  0.000000e+00   \n",
      "...            ...         ...         ...          ...           ...   \n",
      "7248  0.000000e+00         0.0         0.0         0.00  0.000000e+00   \n",
      "7256  7.620450e+04    342187.0    143166.0   9821017.25  3.279092e+05   \n",
      "7261  0.000000e+00         0.0         0.0         0.00  0.000000e+00   \n",
      "7264  7.971476e+06  19900000.0        65.0  10400000.00  4.150499e+06   \n",
      "7266  0.000000e+00         0.0         0.0         0.00  0.000000e+00   \n",
      "\n",
      "        Idle Max   Idle Min   Label  \n",
      "6      5906033.0  5274218.0  BENIGN  \n",
      "8            0.0        0.0  BENIGN  \n",
      "10           0.0        0.0  BENIGN  \n",
      "11           0.0        0.0  BENIGN  \n",
      "13           0.0        0.0  BENIGN  \n",
      "...          ...        ...     ...  \n",
      "7248         0.0        0.0  BENIGN  \n",
      "7256  10000000.0  9127707.0  BENIGN  \n",
      "7261         0.0        0.0  BENIGN  \n",
      "7264  19300000.0  5960934.0  BENIGN  \n",
      "7266         0.0        0.0  BENIGN  \n",
      "\n",
      "[1817 rows x 84 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['random_forest_model.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# Fit and predict using IsolationForest\n",
    "isolation_forest = IsolationForest(contamination=0.25, random_state=42)  # Adjust contamination if needed\n",
    "anomaly_scores_if = isolation_forest.fit_predict(X_scaled)\n",
    "\n",
    "# Fit and predict using RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "labels_rf = np.where(anomaly_scores_if == 1, 1, 0)\n",
    "random_forest.fit(X_scaled, labels_rf)\n",
    "anomaly_predictions_rf = random_forest.predict(X_scaled)\n",
    "\n",
    "# Identify anomalies\n",
    "anomalies_rf = data[anomaly_predictions_rf == 0]\n",
    "\n",
    "print(f\"RandomForest Anomalies: {anomalies_rf}\")\n",
    "\n",
    "# Save the models\n",
    "joblib.dump(isolation_forest, 'isolation_forest_model.pkl')\n",
    "joblib.dump(random_forest, 'random_forest_model.pkl')\n",
    "\n",
    "# Example of loading the models\n",
    "#loaded_autoencoder = tf.keras.models.load_model('autoencoder_model.h5')\n",
    "#loaded_isolation_forest = joblib.load('isolation_forest_model.pkl')\n",
    "#loaded_random_forest = joblib.load('random_forest_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f9993b-43e7-43bf-93dc-8a5dd744a623",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalies detected by autoencoder: 364\n",
      "Number of anomalies detected by RandomForest: 1817\n",
      "Label\n",
      "BENIGN                        5087\n",
      "Web Attack – Brute Force      1507\n",
      "Web Attack – XSS               652\n",
      "Web Attack – Sql Injection      21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of anomalies detected by the autoencoder\n",
    "num_autoencoder_anomalies = len(anomalypoints_autoencoder)\n",
    "print(\"Number of anomalies detected by autoencoder:\", num_autoencoder_anomalies)\n",
    "\n",
    "# Count the number of anomalies detected by the RandomForest\n",
    "num_rf_anomalies = len(anomalies_rf)\n",
    "print(\"Number of anomalies detected by RandomForest:\", num_rf_anomalies)\n",
    "\n",
    "# Count the number of each label in the dataset\n",
    "label_counts = data['Label'].value_counts()\n",
    "print(label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f53726f4-d6f9-4521-bf50-09e3fe08a1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels of RandomForest detected anomalies:\n",
      "Label\n",
      "BENIGN                        1630\n",
      "Web Attack – Brute Force       151\n",
      "Web Attack – XSS                24\n",
      "Web Attack – Sql Injection      12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Labels of autoencoder detected anomalies:\n",
      "Label\n",
      "BENIGN                        340\n",
      "Web Attack – XSS               19\n",
      "Web Attack – Brute Force        4\n",
      "Web Attack – Sql Injection      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cross-check actual labels with detected anomalies for RandomForest\n",
    "anomalies_rf_labels = anomalies_rf['Label'].value_counts()\n",
    "print(\"Labels of RandomForest detected anomalies:\")\n",
    "print(anomalies_rf_labels)\n",
    "print()\n",
    "anomalypoints_autoencoder_labels = anomalypoints_autoencoder['Label'].value_counts()\n",
    "print(\"Labels of autoencoder detected anomalies:\")\n",
    "print(anomalypoints_autoencoder_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6d7fe3c-82b2-477f-887c-cd194659a674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.93      0.79      5087\n",
      "           1       0.07      0.01      0.02      2180\n",
      "\n",
      "    accuracy                           0.66      7267\n",
      "   macro avg       0.38      0.47      0.41      7267\n",
      "weighted avg       0.50      0.66      0.56      7267\n",
      "\n",
      "RandomForest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66      5087\n",
      "           1       0.10      0.09      0.09      2180\n",
      "\n",
      "    accuracy                           0.50      7267\n",
      "   macro avg       0.37      0.38      0.37      7267\n",
      "weighted avg       0.47      0.50      0.49      7267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Create true labels for comparison\n",
    "true_labels = y.map({'BENIGN': 0, 'Web Attack – Brute Force': 1, 'Web Attack – XSS': 1, 'Web Attack – Sql Injection': 1})\n",
    "\n",
    "# For Autoencoder\n",
    "pred_autoencoder = mse > threshold\n",
    "print(\"Autoencoder Classification Report:\")\n",
    "print(classification_report(true_labels, pred_autoencoder))\n",
    "\n",
    "# For RandomForest\n",
    "pred_rf = anomaly_predictions_rf == 0\n",
    "print(\"RandomForest Classification Report:\")\n",
    "print(classification_report(true_labels, pred_rf))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
